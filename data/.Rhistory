data("Wage")
summary(Wage)
inTrain<-createDataPartition(y=Wage$wage, p=0.7, list = FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training)
dim(testing)
dim(training); dim(testing)
featurePlot(x=training[,c("age", "education","jobclass")],y=training$wage, plot = "pairs")
qplot(age, wage, data = training)
qplot(age, wage, color=jobclass, data = training)
qq<-qplot(age, wage, color=education , data = training)
qq+geom_smooth(method = "lm", formula = y~x)
install.packages("Hmisc")
install.packages("Hmisc")
install.packages("Hmisc")
install.packages("Hmisc")
install.packages("Hmisc")
install.packages("Hmisc")
library(Hmisc)
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
library(Hmisc)
cutWage<-cut2(training$wage, g=3)
table(cutWage)
pl<-qplot(cutWage, age, data = training, fill=cutWage, geom = c("boxplot"))
pl
p2<-qplot(cutWage, age, data = training, fill=cutWage, geom = c("boxplot","jitter"))
grid.arrange(pl,p2,ncol=2)
install.packages("gridExtra")
install.packages("gridExtra")
library(gridExtra)
grid.arrange(pl,p2,ncol=2)
t1<-table(cutWage,training$jobclass)
t1
prop.table(t1,1)
library(ggplot2)
qplot(wage, color=education, data = training, geom = "density")
library(caret); library(kernlab); data(spam)
inTrain<-createDataPartition(y=spam$type, p=0.75, list = FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
hist(training$capitalAve, main = "", xlab = "ave. capital run length")
mean(training$capitalAve)
sd
sd(training$capitalAve)
trainCapAve<-training$capitalAve
trainCapAveS<-(trainCapAve-mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd
sd(trainCapAveS)
testCapAve<-testing$capitalAve
ttestCapAveS<-(testCapAve-mean(trainCapAve))/sd(trainCapAve)
mean(ttestCapAveS)
sd(ttestCapAveS)
preObj<-preProcess(training[,-58], method = c("center","scale"))
trainCapAveS<-predict(preObj, training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS<-predict(preObj, testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit<-train(type~.,data = training, preProcess=c("center","scale"), method="glm")
modelFit
preObj<-preProcess(training[-58], method = c("boxCox"))
preObj<-preProcess(training[-58], method = c("BoxCox"))
trainCapAveS<-predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS);qnorm(trainCapAveS)
par(mfrow=c(1,2)); hist(trainCapAveS);qqnorm(trainCapAveS)
set.seed(13343)
training$capAve<-training$capitalAve
selectNA<-rbinom(dim(training)[1], size = 1,prob = .05)==1
training$capAve[selectNA]<-NA
preObj<-preProcess(training[,-58], method = "knnImpute")
capAve<-predict(preObj, training[,-58])$capAve
install.packages("RANN")
capAve<-predict(preObj, training[,-58])$capAve
capAveTruth<-training$capitalAve
capAveTruth<-(capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve~capAveTruth)
quantile(capAve-capAveTruth)
quantile((capAve-capAveTruth)[selectNA])
quantile((capAve-capAveTruth)[!selectNA])
library(ISLR); library(caret); data(Wage);
dim(Wage)
head(Wage)
inTrain<-createDataPartition(y=Wage$wage, p=0.7, list = FALSE)
training<-Wage[inTrain,]; testing<-Wage[-inTrain,]
table(training$jobclass)
dummies<-dummyVars(wage~jobclass, data = training)
head(predict(dummies, newdata=training))
nsv<-nearZeroVar(training,saveMetrics = TRUE)
nsv
library(splines)
bsBasis<-bs(training$age, df=3)
bsBasis
lml<-lm(wage~bsBasis, data = training)
plot(training$age, training$wage, pch=19, cex=0.5)
points(training$age, predict(lml, newdata=training), col="red",pch=19. cex=0.5)
points(training$age, predict(lml, newdata=training), col="red",pch=19, cex=0.5)
predict(bsBasis, age=testing$age)
library(caret); library(kernlab); data("spam")
inTrain<-createDataPartition(y=spam$type, p=.75, list = FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
M<-abs(cor(training[,-58]))
dim(M)
head(M)
diag(M)<-0
which(M>0.8, arr.ind = T)
names(spam)[c(34,40,32)]
plot(spam[,34], spam[,32])
x<-0.71*training$num415+0.71*training$num857
y<-0.71*training$num415-0.71*training$num857
plot(x,y)
smallSpam<-spam[,c(34,32)]
prComp<-prcomp(smallSpam)
plot(prComp$x[,1], prComp$x[,2])
prComp$rotation
typeColor<-((spam$type=="spam")*1+1)
prComp<-prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1], prComp$x[,2], col=typeColor, xlab="PC1", ylab="PC2")
preProc<-preProcess(log10(spam[,-58]+1), method = "pca", pcaComp = 2)
spamPC<-predict(preProc, log10(spam[,-58]+1))
plot(spamPC[,1], spamPC[,2], col=typeColor)
preProc<-preProcess(log10(training[,-58]+1), method = "pca", pcaComp = 2)
trainPC<-predict(preProc, log10(training[,-58]+1))
modelFit<-train(training$type~., method="glm", data = trainPC)
testPC<-predict(preProc, log10(testing[,-58]+1))
confusionMatrix(testing$type, predict(modelFit, testPC))
library(caret); data("faithful"); set.seed(333)
inTrain<-createDataPartition(y=faithful$waiting, p=0.5, list = FALSE)
trainFaith<-faithful[inTrain,]; testFaith<-faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="waiting", ylab="Duration")
lm1<-lm(eruutions~waiting, data = trainFaith)
lm1<-lm(erutions~waiting, data = trainFaith)
lm1<-lm(eruptions~waiting, data = trainFaith)
summary(lm1)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="waiting", ylab="Duration")
lines(trainFaith$waiting, lm1$fitted, lwd=3)
coef(lm1)[1]+coef(lm1)[2]*80
newdata<-data.frame(waiting=80)
predict(lm1, newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue",xlab="waiting", ylab="Duration")
lines(trainFaith$waiting, predict(lm1), lwd=3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue",xlab="waiting", ylab="Duration")
lines(testFaith$waiting, predict(lm1, newdata=testFaith), lwd=3)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1, newdata=testFaith)-testFaith$eruptions)^2))
pred1<-predict(lm1, newdata=testFaith, interval="prediction")
ord<-order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions, pch=19, col="blue")
matlines(testFaith$waiting[ord], pred1[ord,], type = "l", col = c(1,2,2), lty = c(1,1,1), lwd = 3)
modelFit<-train(eruptions~waiting, data = trainFaith, method="lm")
summary(modelFit$finalModel)
library(ISLR); library(ggplot2); library(caret);
data("Wage")
dim(Wage)
head(Wage)
Wage<-subset(Wage, select = c(logwage))
dim(Wage)
summary(Wage)
data("Wage")
Wage<-subset(Wage, select = -c(logwage))
summary(Wage)
inTrain<-createDataPartition(y=Wage$wage, p=0.7, list = FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")], y=training$wage, plot = "pairs")
qplot(age, wage, data = training)
qplot(age, wage,color=jobclass, data = training)
qplot(age, wage,color=education, data = training)
modelFit<-train(wage~age+jobclass+education, method="lm", data = training)
finMod<-modelFit$finalModel
print(modelFit)
plot(finMod,1,pch=19, cex=0.5, col="#00000010")
plot(finMod,1,pch=19, cex=0.5, col="#00000010")
qplot(finMod$fitted, finMod$residuals, color=race, data = training)
plot(finMod$residuals, pch=19)
plot(finMod$residuals, pch=19)
pred<-predict(modelFit, testing)
qplot(wage, pred, color=year, data=testing)
modFit<-train(wage~., data = training, method="lm")
pred<-predict(modFit,testing)
qplot(wage, pred, data = testing)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
head(concrete)
dim(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
dim(training); dim(testing)
dim(mixtures)
head(mixtures)
featurePlot(x=training[,-c("CompressiveStrength")], y=training$CompressiveStrength, plot = "pairs")
featurePlot(x=training[,-c(CompressiveStrength)], y=training$CompressiveStrength, plot = "pairs")
featurePlot(x=training[,-"CompressiveStrength"], y=training$CompressiveStrength, plot = "pairs")
featurePlot(x=training[, names(training)[1:8]], y=training$CompressiveStrength, plot = "pairs")
histogram(mixtures$Superplasticizer)
histogram(concrete$Superplasticizer)
histogram(log10(mixtures$Superplasticizer+1))
concrete$Superplasticizer
x<-concrete$Superplasticizer
x[1:100]
x[100:200]
x[200:300]
x[300:400]
x[400:500]
x[500:600]
x[600:700]
x[700:800]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
data(AlzheimerDisease)
dim(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
set.seed(3433)data(AlzheimerDisease)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(caret)
library(ggplot2)
library(lattice)
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
head(training)[,59:69]
preProc<-preProcess(training[,59:69], method = "pca", pcaComp = 2)
trainPC<-predict(preProc, training[,59:69])
preProc$std
(preProc$std)^2
preProc$numComp
preProc<-preProcess(training[,59:69], method = "pca", thresh = .8)
preProc$numComp
preProc<-preProcess(training[,58:69], method = "pca", thresh = .8)
preProc$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL<-training[,c("diagnosis", 58:69)]
names(training)[1]
trainingIL<-training[,58:69]
trainingIL$diagnosis<-training$diagnosis
dim(trainingIL)
names(trainingIL)
modelFit1<-train(diagnosis~., data = trainingIL, method="glm")
preProc<-preProcess(trainingIL[,-13], method = "pca", thresh = 0.8)
trainPC<-predict(preProc, trainingIL[,-13])
modelFit2<-train(trainingIL$diagnosis~., method="glm", data = trainPC)
testingIL<-testing[,58:69]
testingIL$diagnosis<-testing$diagnosis
dim(testingIL)
confusionMatrix(testingIL$diagnosis, predict(modelFit1, testingIL[,-13]))
data("iris")
library(ggplot2)
names(iris)
table(iris$Species)
library(caret)
library(lattice)
library(caret)
inTrain<-createDataPartition(y=iris$Species, p=0.7,list = FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width, Sepal.Width, color=Species, data = training)
modFit<-train(Species~., method="rpart", data = training)
modFit<-train(Species~., method="rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main="Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = testing)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("ozone", package = "ElemStatLearn")
ozone<-head(ozone)
ozone<-ozone[order(ozone$ozone)]
ozone<-ozone[order(ozone$ozone),]
head(ozone)
package_version("AppliedPredictiveModeling")
packageVersion("AppliedPredictiveModeling")
packageVersion("caret")
packageVersion("ElemStatLearn")
install.packages("pgmm")
packageVersion("pgmm")
packageVersion("rpart")
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
library(caret)
dim(segmentationOriginal)
names(segmentationOriginal)
inTrain<-createDataPartition(y=segmentationOriginal$Case, p=0.7, list = FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
dim(training); dim(testing)
set.seed(125)
library(rpart)
modFit<-train(Case~., method="rpart", data = training)
set.seed(125)
modFit<-train(Case~., method="rpart", data = training)
print(modFit$finalModel)
training[,2][1:5]
segmentationOriginal[,2][1:5]
modFit
head(training)[1:10]
set.seed(125)
modFit<-train(Class~., method="rpart", data = training)
modFit$finalModel
library(rattle)
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
library(rpart)
training<-segmentationOriginal[segmentationOriginal$Case=="Training",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Testing",]
dim(training); dim(testing)
dim(training); dim(testing)
dim(segmentationOriginal)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(train); dim(test)
dim(training); dim(testing)
dim(segmentationOriginal)
set.seed(125)
modFit<-train(Class~., method="rpart", data = training)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(segmentationOriginal)
names(segmentationOriginal)[1:5]
segmentationOriginal[,2][1:5]
dim(training); dim(testing)
library(rpart)
set.seed(125)
fitMod<-train(Class~., method="rpart", data = training)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(fitMod$finalModel)
library(pgmm)
data("olive")
dim(olive)
names(olive)
head(olive)
olive<-olive[,-1]
head(olive)
tail(olive)
modFit<-train(Area~., method="rpart", data = olive)
plot(modFit$finalModel, uniform = TRUE, main="Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=0.8)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata)
library(ElemStatLearn)
data("SAheart")
dim(SAheart)
names(SAheart)
head(SAheart)
tail(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
?glm
set.seed(13234)
trainFit<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl, data = trainSA, family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass()
missClass
summary(trainFit)
prediction<-predict(trainFit)
length(prediction)
prediction
values<-trainSA[,10]
length(values)
values
x<-trainFit$fitted.values
length(x)
x
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
misClass
mc<- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
mc
mc<- sum(((prediction > 0.5)*1) != values)/length(values)
mc
set.seed(13234)
testFit<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl, data = testSA, family = "binomial")
prediction<-predict(testFit)
values<-testSA[,10]
mc2<- sum(((prediction > 0.5)*1) != values)/length(values)
mc2
prediction<-predict(trainFit, newdata = testSA)
mc2<- sum(((prediction > 0.5)*1) != values)/length(values)
mc2
set.seed(13234)
library(caret)
set.seed(13234)
dim(trainSA)
dim(testSA)
?train
library(caret)
modSA<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
names(trainSA)
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
library(caret)
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
library(caret)
library(caret)
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
inTrain = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA<-SAheart[inTrain,]
testSA<-SAheart[-inTrain,]
dim(trainSA); dim(testSA)
set.seed(13234)
modSA<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family="binomial", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, prediction = predict(modSA))
missClass(testSA$chd, prediction = predict(modSA, newdata = testSA))
library(ElemStatLearn)
data("vowel.train")
data("vowel.test")
dim(vowel.test)
dim(vowel.train)
names(vowel.test)
names(vowel.train)
head(vowel.test)
head(vowel.train)
vowel.test$y<-factor(vowel.test$y)
vowel.train$y<-factor(vowel.train$y)
set.seed(33833)
modFit<-train(y~., data = vowel.train, mathod="rf", prox=TRUE)
varImp(modFit)
randomForest(modFit)
set.seed(33833)
modFit<-train(y~., data = vowel.train, mathod="rf", prox=TRUE)
varImp(modFit)
?randomForest
library(ElemStatLearn)
data("vowel.test")
data("vowel.train")
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
modFit<-randomForest(y~., data = vowel.train)
varImp(modFit)
order(varImp(modFit), decreasing = TRUE)
modFit2<-train(y~., data = vowel.train, mathod="rf", prox=TRUE)
varImp(modFit2)
setwd("~/Google Drive/Data Science/Practical Machine Learning/Week4/Course Project/data")
training<-read.csv("pml-training.csv")
dim(training)
names(training)
testing<-read.csv("pml-testing.csv")
dim(testing)
names(testing)
training[,160][1:10]
training[,160][1:50]
training[,160][1000:1020]
training[,160][10000:10020]
